{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3746ec74-e095-4110-a01c-ada9310e3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f579ee80-e50d-480a-aca1-ba7c5431843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4000 = pd.read_csv(\".//Data/4000/4000-stories-VAD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5182c73-f231-48e8-b151-24dc2a1286e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>length</th>\n",
       "      <th>title</th>\n",
       "      <th>text_no</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>text_id</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://americanliterature.com/author/eleanor-...</td>\n",
       "      <td>15044</td>\n",
       "      <td>Peace on Earth, Good-Will to Dogs</td>\n",
       "      <td>0</td>\n",
       "      <td>Eleanor Hallowell Abbott</td>\n",
       "      <td>PART I\\n\\nIf you don't like Christmas stories,...</td>\n",
       "      <td>0.592896</td>\n",
       "      <td>0.397839</td>\n",
       "      <td>0.569567</td>\n",
       "      <td>0_eleanor-hallowell-abbott-peace-on-earth-good...</td>\n",
       "      <td>...</td>\n",
       "      <td>3.793141</td>\n",
       "      <td>3.837345</td>\n",
       "      <td>3.778354</td>\n",
       "      <td>-0.815515</td>\n",
       "      <td>-0.72044</td>\n",
       "      <td>-10.738245</td>\n",
       "      <td>-8.765683</td>\n",
       "      <td>0.875089</td>\n",
       "      <td>-10.176691</td>\n",
       "      <td>1.736791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  length  \\\n",
       "0  https://americanliterature.com/author/eleanor-...   15044   \n",
       "\n",
       "                               title  text_no                    author  \\\n",
       "0  Peace on Earth, Good-Will to Dogs        0  Eleanor Hallowell Abbott   \n",
       "\n",
       "                                               story   valence   arousal  \\\n",
       "0  PART I\\n\\nIf you don't like Christmas stories,...  0.592896  0.397839   \n",
       "\n",
       "   dominance                                            text_id  ...  \\\n",
       "0   0.569567  0_eleanor-hallowell-abbott-peace-on-earth-good...  ...   \n",
       "\n",
       "        290       291       292       293      294        295       296  \\\n",
       "0  3.793141  3.837345  3.778354 -0.815515 -0.72044 -10.738245 -8.765683   \n",
       "\n",
       "        297        298       299  \n",
       "0  0.875089 -10.176691  1.736791  \n",
       "\n",
       "[1 rows x 317 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4000.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6bae71-6f25-44f2-9ec2-18bc9e98d859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'length', 'title', 'text_no', 'author', 'story', 'valence',\n",
       "       'arousal', 'dominance', 'text_id',\n",
       "       ...\n",
       "       '290', '291', '292', '293', '294', '295', '296', '297', '298', '299'],\n",
       "      dtype='object', length=317)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4000.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5df18b45-8ca6-4bc7-a8a0-6141c03f422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100       84\n",
      "101      141\n",
      "102      141\n",
      "103      140\n",
      "104      191\n",
      "       ...  \n",
      "194    16642\n",
      "195      817\n",
      "196     7148\n",
      "197    13519\n",
      "198     5221\n",
      "Name: length, Length: 99, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "lengths = text4000['length'][100:199]\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7397919-0a6f-4e15-ae71-d6e8c10e4ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Gnat flew over the meadow with much buzzing for so small a creature and settled on the tip of one of the horns of a Bull. After he had rested a short time, he made ready to fly away. But before he left he begged the Bull\\'s pardon for having used his horn for a resting place.\\n\\n\"You must be very glad to have me go now,\" he said.\\n\\n\"It\\'s all the same to me,\" replied the Bull. \"I did not even know you were there.\"\\n\\nWe are often of greater importance in our own eyes than in the eyes of our neighbor.\\n\\nThe smaller the mind the greater the conceit.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4000['story'][99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e483472-608e-4253-98a0-17dd12409c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts= list(text4000.story.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6799780-03cd-4c57-a3e1-9a42eda64f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Texte mit Trennzeichen oder speziellem Wort kombinieren\n",
    "trennzeichen = \"trennzeichen\"\n",
    "joined_text = (\" \" + trennzeichen + \" \").join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38ca8a0-a997-48a0-a2d5-1cb467d1aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer erstellen und Texte darauf anwenden\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(joined_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c540333-3dd5-4554-9e3c-ac86c9e56f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "context_words = 10\n",
    "input_words = []\n",
    "next_words = []\n",
    "words_limiter = 200000  # limitiert die Anzahl an Trainingsdaten\n",
    "counter=0\n",
    "i = 0\n",
    "while i < len(tokens) - context_words:\n",
    "    if tokens[i + context_words] == trennzeichen:\n",
    "        i += context_words + 1\n",
    "        counter+=1\n",
    "        continue  # Eintrag überspringen, wenn das Trennzeichen erreicht wird\n",
    "    \n",
    "    input_words.append(tokens[i:i + context_words])\n",
    "    next_words.append(tokens[i + context_words])\n",
    "    \n",
    "    if len(next_words) >= words_limiter:\n",
    "        break\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(len(next_words))\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38ffaad5-4406-4d89-b3b4-f50e1ab86de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alles Gut. Das Trennzeichen ist in tokens enthalten.\n",
      "Alles Gut.\n",
      "Alles Gut.\n"
     ]
    }
   ],
   "source": [
    "# überprüfen ob alles ok mit dem Trennzeichen ist\n",
    "if trennzeichen in tokens:\n",
    "    print(\"Alles Gut. Das Trennzeichen ist in tokens enthalten.\")\n",
    "else:\n",
    "    print(\"Fehler!!! Trennzeichen nicht in tokens!!!\")\n",
    "if trennzeichen in input_words:\n",
    "    print(\"Fehler!!! Das Trennzeichen ist in input_words enthalten.!!!\")\n",
    "else:\n",
    "    print(\"Alles Gut.\")\n",
    "if trennzeichen in next_words:\n",
    "    print(\"Fehler!!! Das Trennzeichen ist in next_words enthalten.!!!\")\n",
    "else:\n",
    "    print(\"Alles Gut.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7eceeaa-0c1e-4bcd-aaf6-e87136390ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_tokens = [token for sublist in input_words for token in sublist]\n",
    "unique_tokens = np.unique(np.concatenate((input_tokens, next_words))) #alle Token 108282 || in 50000 Token sind 7359 unique\n",
    "unique_token_index = {token: idx for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89130dd6-2574-406c-b26c-6990aafc27a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14353"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efdf27fe-683e-4971-9e9b-1c48a1f84983",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_words), context_words, len(unique_tokens)), dtype=bool)\n",
    "Y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96fec496-140e-44a3-a136-9fc354ac43f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i,j, unique_token_index[word]] = 1\n",
    "    Y[i, unique_token_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb2977e5-6387-4f50-a9fb-cebd3e0cc98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilung der Trainings- und Validierungsdaten\n",
    "split_index = int(len(X) * 0.95)\n",
    "x_train, x_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = Y[:split_index], Y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e00f0b-e4a9-493f-8273-18ae443f0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FormatedData/200000_fixed/x_train.pickle', 'wb') as file:\n",
    "    pickle.dump(x_train, file)\n",
    "with open('FormatedData/200000_fixed/x_val.pickle', 'wb') as file:\n",
    "    pickle.dump(x_val, file)\n",
    "with open('FormatedData/200000_fixed/y_train.pickle', 'wb') as file:\n",
    "    pickle.dump(y_train, file)\n",
    "with open('FormatedData/200000_fixed/y_val.pickle', 'wb') as file:\n",
    "    pickle.dump(y_val, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a30f9f2-9bde-4577-82f0-560b73a9e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FormatedData/200000_fixed/MetaData/context_words.pickle', 'wb') as file:\n",
    "    pickle.dump(context_words, file)\n",
    "with open('FormatedData/200000_fixed/MetaData/unique_tokens.pickle', 'wb') as file:\n",
    "    pickle.dump(unique_tokens, file)\n",
    "with open('FormatedData/100000_fixed/MetaData/unique_token_index.pickle', 'wb') as file:\n",
    "    pickle.dump(unique_token_index, file)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
